{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aneesha17/dino/blob/main/video.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rxgJp5ZbYmSP",
        "outputId": "5f5551d2-10bd-4b77-8954-fab5575e26bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'dino'...\n",
            "remote: Enumerating objects: 175, done.\u001b[K\n",
            "remote: Counting objects: 100% (69/69), done.\u001b[K\n",
            "remote: Compressing objects: 100% (15/15), done.\u001b[K\n",
            "remote: Total 175 (delta 57), reused 55 (delta 54), pack-reused 106\u001b[K\n",
            "Receiving objects: 100% (175/175), 24.44 MiB | 12.60 MiB/s, done.\n",
            "Resolving deltas: 100% (109/109), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/aneesha17/dino/"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd dino"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0G1ajSHXZLOW",
        "outputId": "0e2cecdb-bc59-4d3e-d4b7-ee6be78ef266"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/dino\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python video_generation.py  --pretrained_weights dino_deitsmall8_pretrain.pth \\\n",
        "    --input_path /content/example.mp4 \\\n",
        "    --output_path output/ \\\n",
        "    --fps 25"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "60ORQYTEZNjx",
        "outputId": "c33c54e5-7fa0-4167-c51e-745977e6fdda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please use the `--pretrained_weights` argument to indicate the path of the checkpoint to evaluate.\n",
            "Since no pretrained weights have been provided, we load the reference pretrained DINO weights.\n",
            "Video: /content/example.mp4 (25.0 fps)\n",
            "Extracting frames to output/frames\n",
            "Generating attention images to output/attention\n",
            " 94% 374/400 [1:53:02<08:12, 18.94s/it]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python video_generation.py  --pretrained_weights dino_deitsmall8_pretrain.pth \\\n",
        "    --input_path output/frames/ \\\n",
        "    --output_path output/ \\\n",
        "    --resize 256"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UxE9WNKfZSj5",
        "outputId": "76a6debe-d06c-4bb0-e0b1-c52602d3b8f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please use the `--pretrained_weights` argument to indicate the path of the checkpoint to evaluate.\n",
            "Since no pretrained weights have been provided, we load the reference pretrained DINO weights.\n",
            "Generating attention images to output/attention\n",
            "\r  0% 0/400 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "100% 400/400 [34:00<00:00,  5.10s/it]\n",
            "Generating video (448, 256) to output/\n",
            "100% 399/399 [00:00<00:00, 869.54it/s]\n",
            "OpenCV: FFMPEG: tag 0x5634504d/'MP4V' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
            "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
            "Done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python video_generation.py --input_path output/attention \\\n",
        "    --output_path output/ \\\n",
        "    --video_only \\\n",
        "    --video_format avi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9XpDAJnuZUzT",
        "outputId": "779d03ff-b898-43b6-ce27-7885dde51381"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating video (640, 360) to output/\n",
            "100% 114/114 [00:00<00:00, 408.60it/s]\n",
            "Done\n"
          ]
        }
      ]
    }
  ]
}